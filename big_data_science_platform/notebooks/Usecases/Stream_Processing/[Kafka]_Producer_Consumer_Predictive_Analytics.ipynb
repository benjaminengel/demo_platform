{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- DB Anbindung\n",
    "- Bugfix while Schleife"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden anhand des Iris Datensatzes eine einfache Predictive Pipeline in Python Demonstrieren.\n",
    "\n",
    "* Irirs Datensatz wird aufgespallten Streaming Data, Training Data\n",
    "* Auf dem trainings Teil wird ein Modell Trainiert\n",
    "* Der Streaming Teil wird Ã¼ber einen Producer in Kafka gestreamt unter dem Topic 'iris'\n",
    "* Der Consumer lauscht auf das Topic 'iris' und nimmt die Messages entgegen, betreibt inference und schreibt die Daten und das Modell Ergebniss in die MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from confluent_kafka         import Producer, Consumer\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import threading\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Laden und vorbereiten der Daten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "if VERBOSE:\n",
    "    print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [e.replace(' ','_').replace('(cm)','in_cm') for e in data.feature_names]\n",
    "X_stream, X_train, y_stream, y_train = train_test_split(data['data'], data['target'])\n",
    "X_stream = pd.DataFrame(X_stream, columns=feature_names)\n",
    "X_train  = pd.DataFrame(X_train, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainieren des Modells auf historischen Daten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    for n_neighbors in range(1,X_train.shape[0]-5):\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        print(\"%s : %s\" % (n_neighbors,\n",
    "                           cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 17\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstellen eines Kafka Producers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Config\n",
    "TOPIC = 'iris'\n",
    "BOOTSTRAP_SERVERS = 'kafka1:19092,kafka2:29092,kafka3:39092'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_callback(err, msg):\n",
    "    if err:\n",
    "        print('%% Message failed delivery: %s\\n' % err)\n",
    "    else:\n",
    "        if VERBOSE:\n",
    "            print('%% Message delivered to %s [%d] @ %o\\n' %\n",
    "                             (msg.topic(), msg.partition(), msg.offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Producer({'bootstrap.servers': BOOTSTRAP_SERVERS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_msgs():\n",
    "    for msg in msgs:\n",
    "        p.produce(TOPIC, msg, callback=delivery_callback)\n",
    "        p.poll(10)\n",
    "    p.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vorbereiten der Nachrichten*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [ str(e) for e in eval(X_stream.to_json(orient='records'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstellen eines Kafka Consumers ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "        'bootstrap.servers': BOOTSTRAP_SERVERS,\n",
    "        'group.id': 'mygroup', \n",
    "        'default.topic.config': {\n",
    "            'auto.offset.reset': 'smallest'\n",
    "        }\n",
    "}\n",
    "\n",
    "c = Consumer(config_dict)\n",
    "c.subscribe([TOPIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_and_process_msg():\n",
    "    msg = c.poll()\n",
    "    if not msg.value():\n",
    "        raw = eval(msg.value())\n",
    "        model_input = np.array([raw[k] for k in list(X_train.columns)]).reshape(1, -1)\n",
    "        y_ = knn.predict(model_input)[0]\n",
    "        if VERBOSE:\n",
    "            print(\"Input %s => Prediction %s\" % (raw, y_))\n",
    "        #write to db\n",
    "        return True\n",
    "    logging.error(\"Can't eval %s\" % msg.value())\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_thread = threading.Thread(target=push_msgs)\n",
    "producer_thread.start()\n",
    "\n",
    "end_of_data = False\n",
    "\n",
    "while not end_of_data:\n",
    "    if not producer_thread.is_alive and not pull_and_process_msg():\n",
    "        if VERBOSE:\n",
    "            print('Producer running: ', producer_thread.is_alive())\n",
    "        end_of_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
